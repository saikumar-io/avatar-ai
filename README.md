# ğŸ§  Multilingual Digital Human Avatar

A real-time 3D talking avatar that understands text or speech and responds in multiple Indian languages with synchronized lip movements and animations.

This system combines:

- ğŸ§  **Groq (LLaMA 3.3)** â€” AI Brain  
- ğŸ—£ **Sarvam AI** â€” Multilingual Text-to-Speech & Speech-to-Text  
- ğŸ‘„ **Rhubarb Lip Sync** â€” Viseme generation  
- ğŸ­ **React + Three.js** â€” 3D Avatar rendering  
- âš¡ **Express (Node.js)** â€” Avatar audio + lip-sync engine  
- ğŸ **Flask (Python)** â€” AI + Language backend  

---

# ğŸ— System Architecture

```
User
  â†“
Frontend (React + Three.js)
  â†“
Python Backend (Groq + Sarvam)
  â†“
Node Avatar Engine (Audio + LipSync)
  â†“
3D Avatar with animations
```

---

# ğŸ“ Project Structure

```
avatar-ai/
â”‚
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ frontend/        â†’ React + Three.js UI
â”‚   â””â”€â”€ backend/         â†’ Node Avatar Engine (TTS bridge + Rhubarb)
â”‚
â””â”€â”€ services/
    â””â”€â”€ python-api/      â†’ Flask AI Backend (Groq + Sarvam)
```

---

# ğŸš€ Features

- âœ… Text-based chat
- ğŸ¤ Voice input (microphone support)
- ğŸŒ Multilingual responses:
  - English (en-IN)
  - Hindi (hi-IN)
  - Telugu (te-IN)
  - Tamil (ta-IN)
  - Kannada (kn-IN)
- ğŸ‘„ Real-time lip sync
- ğŸ˜Š Facial expressions
- ğŸ¬ Idle + talking animations
- ğŸ”„ Language switching mid-conversation
- ğŸ‘¨ Male voice support (Sarvam configuration)

---

# âš™ï¸ Requirements

Install the following before running the project:

- **Node.js (v18+)**
- **Python 3.10+**
- **FFmpeg**
- **Rhubarb Lip Sync**

### Download Rhubarb

Official repository:
https://github.com/DanielSWolf/rhubarb-lip-sync/releases

After downloading:

Place the extracted files inside:

```
apps/backend/bin/
```

On Linux / Mac:

```
chmod +x rhubarb
```

---

# ğŸ§  Python AI Backend Setup (Groq + Sarvam)

Navigate to:

```
cd services/python-api
```

Create virtual environment:

```
python -m venv venv
source venv/bin/activate
```

Install dependencies:

```
pip install -r requirements.txt
```

Create a `.env` file:

```
GROQ_API_KEY=your_groq_api_key
SARVAM_API_KEY=your_sarvam_api_key
```

Start backend:

```
python app.py
```

Runs at:

```
http://127.0.0.1:5000
```

---

# ğŸ‘„ Node Avatar Backend Setup (LipSync Engine)

Navigate to:

```
cd apps/backend
```

If using Bun:

```
bun install
bun run server
```

If using Node:

```
npm install
node server.js
```

Runs at:

```
http://localhost:3000
```

This service:

- Receives AI-generated text
- Calls Python TTS
- Saves MP3 audio
- Runs Rhubarb lip-sync
- Returns audio + viseme data to frontend

---

# ğŸ­ Frontend Setup (React + Three.js)

Navigate to:

```
cd apps/frontend
```

If using Bun:

```
bun install
bun run dev
```

If using Node:

```
npm install
npm run dev
```

Open browser:

```
http://localhost:5173
```

---

# ğŸ”Š Voice System

Current configuration:

- English / Hindi / Tamil â†’ High-quality TTS
- Telugu / Kannada â†’ Sarvam multilingual neural voice
- Male voice enabled via Sarvam speaker configuration

---

# ğŸ¥ How It Works

## Text Flow

1. User types message  
2. Python backend sends to Groq LLM  
3. AI response generated  
4. Sarvam TTS produces audio  
5. Node backend runs Rhubarb  
6. Viseme data returned  
7. Avatar speaks with lip-sync  

---

## Voice Flow

1. User speaks via microphone  
2. Sarvam STT converts speech â†’ text  
3. Text sent to Groq  
4. Response generated  
5. Sarvam TTS produces audio  
6. Rhubarb generates visemes  
7. Avatar speaks with synchronized lips  

---

# ğŸ§¹ Architecture Design

The system is intentionally separated into:

- ğŸ Python â†’ AI + Language Processing  
- âš¡ Node â†’ Audio + LipSync Engine  
- ğŸ­ Frontend â†’ 3D Rendering  

This makes it easy to:

- Replace TTS providers  
- Upgrade LLM models  
- Deploy services independently  
- Scale backend services  

---

# ğŸ›  Development Notes

- Restart Node backend after modifying Rhubarb configuration
- Restart Python backend after language changes
- Clear `apps/backend/audios/` if files accumulate
- Ensure FFmpeg is accessible globally (`ffmpeg -version`)

---

# ğŸ“Œ Future Improvements

- Streaming LLM responses
- Emotion-based voice synthesis
- Real-time WebRTC voice chat
- Docker deployment
- Persistent chat memory
- Voice cloning

---

# ğŸ‘¨â€ğŸ’» Author

Built as a multilingual interactive AI digital human system using modern LLM and speech technologies.
